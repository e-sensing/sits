% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sits_torch_linear.R
\name{torch_linear_relu_dropout}
\alias{torch_linear_relu_dropout}
\title{Torch module for linear transformation with relu activation and dropout}
\usage{
torch_linear_relu_dropout(input_dim, output_dim, dropout_rate)
}
\arguments{
\item{input_dim}{Input dimension of neural net.}

\item{output_dim}{Output dimension of neural net.}

\item{dropout_rate}{Dropout rate for linear module.}
}
\value{
A linear tensor block.
}
\description{
Defines a torch module composed of; (a) linear transformation;
(b) relu activation; (c) dropout
}
\author{
Charlotte Pelletier, \email{charlotte.pelletier@univ-ubs.fr}

Gilberto Camara, \email{gilberto.camara@inpe.br}

Rolf Simoes, \email{rolf.simoes@inpe.br}

Felipe Souza, \email{lipecaso@gmail.com}
}
\keyword{internal}
