% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sits_tempcnn.R
\name{sits_tempcnn}
\alias{sits_tempcnn}
\alias{sits_TempCNN}
\title{Train temporal convolutional neural network models}
\usage{
sits_TempCNN(
  samples = NULL,
  samples_validation = NULL,
  cnn_layers = c(64, 64, 64),
  cnn_kernels = c(5, 5, 5),
  cnn_dropout_rates = c(0.5, 0.5, 0.5),
  dense_layer_nodes = 256,
  dense_layer_dropout_rate = 0.5,
  epochs = 150,
  batch_size = 128,
  validation_split = 0.2,
  optimizer = optim_adabound,
  learning_rate = 0.001,
  lr_decay_epochs = 1,
  lr_decay_rate = 1,
  patience = 20,
  min_delta = 0.01,
  verbose = FALSE
)
}
\arguments{
\item{samples}{Time series with the training samples.}

\item{samples_validation}{Time series with the validation samples. if the
\code{samples_validation} parameter is provided,
the \code{validation_split} parameter is ignored.}

\item{cnn_layers}{Number of 1D convolutional filters per layer}

\item{cnn_kernels}{Size of the 1D convolutional kernels.}

\item{cnn_dropout_rates}{Dropout rates for 1D convolutional filters.}

\item{dense_layer_nodes}{Number of nodes in the dense layer.}

\item{dense_layer_dropout_rate}{Dropout rate (0,1) for the dense layer.}

\item{epochs}{Number of iterations to train the model.}

\item{batch_size}{Number of samples per gradient update.}

\item{validation_split}{Fraction of training data to be used for
validation.}

\item{optimizer}{Optimizer function to be used.}

\item{learning_rate}{Initial learning rate of the optimizer.}

\item{lr_decay_epochs}{Number of epochs to reduce learning rate.}

\item{lr_decay_rate}{Decay factor for reducing learning rate.}

\item{patience}{Number of epochs without improvements until
training stops.}

\item{min_delta}{Minimum improvement to reset the patience counter.}

\item{verbose}{Verbosity mode (TRUE/FALSE). Default is FALSE.}
}
\value{
A fitted model to be passed to \code{\link[sits]{sits_classify}}
}
\description{
Use a TempCNN algorithm to classify data, which has
two stages: a 1D CNN and a  multi-layer perceptron.
Users can define the depth of the 1D network, as well as
the number of perceptron layers.

This function is based on the paper by Charlotte Pelletier referenced below.
If you use this method, please cite the original tempCNN paper.

The torch version is based on the code made available by the BreizhCrops
team: Marc Russwurm, Charlotte Pelletier, Marco Korner, Maximilian Zollner.
The original python code is available at the website
https://github.com/dl4sits/BreizhCrops. This code is licensed as GPL-3.
}
\examples{
\dontrun{
# Retrieve the set of samples for the Mato Grosso (provided by EMBRAPA)

# Build a machine learning model based on deep learning
tc_model <- sits_train(samples_modis_4bands, sits_tempcnn())
# Plot the model
plot(tc_model)

# get a point and classify the point with the ml_model
point <- sits_select(point_mt_6bands, bands = c("NDVI", "EVI", "NIR", "MIR"))
class <- sits_classify(point, tc_model)

plot(class, bands = c("NDVI", "EVI"))
}
}
\references{
Charlotte Pelletier, Geoffrey Webb and FranÃ§ois Petitjean,
"Temporal Convolutional Neural Network for the Classification
of Satellite Image Time Series",
Remote Sensing, 11,523, 2019. DOI: 10.3390/rs11050523.
}
\author{
Charlotte Pelletier, \email{charlotte.pelletier@univ-ubs.fr}

Gilberto Camara, \email{gilberto.camara@inpe.br}

Rolf Simoes, \email{rolf.simoes@inpe.br}

Felipe Souza, \email{lipecaso@gmail.com}
}
