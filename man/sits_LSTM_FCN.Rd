% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sits_deep_learning.R
\name{sits_LSTM_FCN}
\alias{sits_LSTM_FCN}
\title{Train a model using the a combination of LSTM and CNN}
\usage{
sits_LSTM_FCN(data = NULL, lstm_units = 8, lstm_dropout = 0.8,
  cnn_layers = c(128, 256, 128), cnn_kernels = c(8, 5, 3),
  activation = "relu", optimizer = keras::optimizer_adam(lr = 0.001),
  epochs = 150, batch_size = 128, validation_split = 0.2,
  verbose = 1, binary_classification = FALSE)
}
\arguments{
\item{data}{Time series with the training samples.}

\item{lstm_units}{Number of cells in the each LSTM layer}

\item{lstm_dropout}{Dropout rate of the LSTM module}

\item{cnn_layers}{Vector with the number of filters for each 1D CNN layer.}

\item{cnn_kernels}{Vector with the size of the 1D convolutional kernels.}

\item{activation}{Activation function for 1D convolution.
Valid values are {'relu', 'elu', 'selu', 'sigmoid'}.}

\item{optimizer}{Function with a pointer to the optimizer function (default is optimization_adam()).
Options are optimizer_adadelta(), optimizer_adagrad(), optimizer_adam(),
optimizer_adamax(), optimizer_nadam(), optimizer_rmsprop(), optimizer_sgd()}

\item{epochs}{Number of iterations to train the model.}

\item{batch_size}{Number of samples per gradient update.}

\item{validation_split}{Number between 0 and 1. Fraction of the training data to be used as validation data.
The model will set apart this fraction of the training data, will not train on it,
and will evaluate the loss and any model metrics on this data at the end of each epoch.
The validation data is selected from the last samples in the x and y data provided,
before shuffling.}

\item{verbose}{Verbosity mode (0 = silent, 1 = progress bar, 2 = one line per epoch).}

\item{binary_classification}{A lenght-one logical indicating if this is a binary classification. If it is so,
the number of unique labels in the training data must be two as well.}
}
\value{
A model fitted to input data to be passed to \code{\link[sits]{sits_classify}}
}
\description{
Use a combination of an LSTM (Long Short Term Memory) and a
cascade of 1D-CNN newtorks to classify data. Users can define the number of
convolutional layers, the size of the convolutional
kernels, and the activation functions.

#' This function is based on the paper by Karim et al. referenced below
and the code made available on github (https://github.com/titu1994/LSTM-FCN)
If you use this method, please cite the original paper.
}
\examples{
\donttest{
# Retrieve the set of samples for the Mato Grosso region (provided by EMBRAPA)

# Build a machine learning model based on deep learning
lstm_cnn_model <- sits_train (samples_mt_4bands, sits_LSTM_FCN())

# plot the model
plot(lstm_cnn_model)

# get a point and classify the point with the ml_model
point.tb <- sits_select_bands(point_mt_6bands, ndvi, evi, nir, mir)
class.tb <- sits_classify(point.tb, lstm_cnn_model)
plot(class.tb, bands = c("ndvi", "evi"))
}
}
\references{
Fazle Karim, Somshubra Majumdar, Houshang Darabi, Sun Chen,
"LSTM fully convolutional networks for time series classification", IEEE Access, 6(1662-1669), 2018.
}
\author{
Gilberto Camara, \email{gilberto.camara@inpe.br}

Alexandre Xavier Ywata de Carvalho, \email{alexandre.ywata@ipea.gov.br}

Rolf Simoes, \email{rolf.simoes@inpe.br}
}
